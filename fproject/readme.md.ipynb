{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "036148f8",
   "metadata": {},
   "source": [
    "<img src=\"Slackimage.png\" width=\"200\" height=\"\">\n",
    "\n",
    "\n",
    "\n",
    "NLP analysis of a small online chat group\n",
    "=========================================\n",
    "\n",
    "Introduction\n",
    "------------\n",
    "\n",
    "Natural Language Processing offers the possibility to analyse free\n",
    "flowing conversations and generate insights over large texts and\n",
    "transcripts. This project aims to investigate the potential of NLP to\n",
    "provide insights into the conversations on a small chat group.\n",
    "\n",
    "\n",
    "Aims\n",
    "----\n",
    "\n",
    "I am keen to discover the potential of NLP to show user intent,\n",
    "interests, pain points and behaviours. This project aims to create an\n",
    "analysis model that assesses the messaging type and participation levels\n",
    "in a small slack groups. Aims include:\n",
    "\n",
    "-   Create a model that categorises interaction types, ranks users,\n",
    "    assesses value and spots repetition.\n",
    "\n",
    "-   Leverage my familiarity with the channel to help create a model that\n",
    "    is appropriate to it – while coding in flexibilities so that the\n",
    "    model can be applied elsewhere.\n",
    "\n",
    "-   Produce recommendations for more efficient and successful slack\n",
    "    interactions for organisations and individuals.\n",
    "\n",
    "About the IronHack slack group\n",
    "------------------------------\n",
    "\n",
    "The dataset is the complete record of the communications between\n",
    "students of IronHack on their group Slack channel between March\n",
    "18<sup>th</sup> and April 27<sup>th</sup> 2021. As the group was\n",
    "relatively small (29 user profiles) and the conversation tended to\n",
    "happen principally in one channel, I decided to focus just on this\n",
    "‘general’ channel.\n",
    "\n",
    "I have the advantage of knowing much of the content and context of the\n",
    "conversations that have happened in this channel already. While this\n",
    "could be seen as a problem as it potentially biases my approach to the\n",
    "data, it is also an advantage. My familiarity with the content allows me\n",
    "to build a model that is shaped to the characteristics of group\n",
    "conversation. This should allow me to make more accurate model, know\n",
    "where to look and what to expect.\n",
    "\n",
    "Also, it is not unrealistic to expect to have a considerable amount of\n",
    "prior knowledge about the nature of a conversation in other Slack\n",
    "channels I might want to analyse in the future.\n",
    "\n",
    "Here are some expected characteristics of the IronHack group chat:\n",
    "\n",
    "-   Largely positive sentiment. To my knowledge there have been\n",
    "    virtually no disputes within the group. It is a small supportive\n",
    "    group of people come together to achieve a common purpose and only\n",
    "    for a short time and working remotely. All this means there is\n",
    "    little chance for tensions or disputes and the mood is\n",
    "    overwhelmingly positive\n",
    "\n",
    "-   While there is some ‘chatter’ on the channel, it’s generally a\n",
    "    practical channel for information sharing and course organisation. I\n",
    "    expect the core message types to be:  \n",
    "    - Information sharing  \n",
    "    - Question/Problem posing  \n",
    "    - Solution/Answers  \n",
    "    - General encouragement  \n",
    "    - Humour  \n",
    "    - Gratitude\n",
    "\n",
    "Defining Success\n",
    "----------------\n",
    "\n",
    "One challenge will be to define what success is. If we are to make\n",
    "useful recommendations then we some success criteria. Here are some\n",
    "suggestions of what success is or isn’t:\n",
    "\n",
    "For individuals:\n",
    "\n",
    "-   No of likes\n",
    "\n",
    "-   No of replies\n",
    "\n",
    "-   Expressions of gratitude\n",
    "\n",
    "-   Contributor v. Problem poser score (net contributor score?)\n",
    "\n",
    "For admins:\n",
    "\n",
    "-   Repetition in or across channels (less repetition = good)\n",
    "\n",
    "-   Issues resolved/unresolved (lost conversations?)\n",
    "\n",
    "-   Channel clarity/discipline score\n",
    "\n",
    "-   Overall activity and engagement rates\n",
    "\n",
    "For organisation:\n",
    "\n",
    "-   Overall sentiment\n",
    "\n",
    "-   List of brand mentions and links\n",
    "\n",
    "-   Flagging problems\n",
    "\n",
    "Process\n",
    "-------\n",
    "\n",
    "1.  Importing and joining json files into one dataframe in Python (data\n",
    "    came in daily json files)\n",
    "\n",
    "2.  Cleaning and Wrangling the data.\n",
    "\n",
    "3.  Processing in the DataFrame for attributable ‘scores’ and\n",
    "    characteristics per post.\n",
    "\n",
    "4.  Combining all text into one TextBlob in order to run TextBlob\n",
    "    functions such as n-gram and noun-phrase extraction\n",
    "\n",
    "5.  Returning two csv files\n",
    "\n",
    "6.  Realising insights visually in Tableau."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1980a22e",
   "metadata": {},
   "source": [
    "Basic stats about the Slack Conversation\n",
    "----------------------------------------\n",
    "\n",
    "597 Messages  \n",
    "81 Threads  \n",
    "132 Questions  \n",
    "153 emojis and reactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9008bfe8",
   "metadata": {},
   "source": [
    "Sentiment\n",
    "---------\n",
    "\n",
    "Ran a basic sentiment analysis that with a spot check seemed to\n",
    "accurately grade the varies in positivity of language used. This could\n",
    "be very useful for analysing other chat groups, but was not that\n",
    "relevant for this example. The group conversation was almost entirely\n",
    "free of negative comments, so even those with the lowest polarity rating\n",
    "were really fairly neutral comments (only went as negative as -0.2 on a\n",
    "scale that stretches to negative 0.5). The sentiment ranking was for\n",
    "this reason in three categories that were not negative: Positive,\n",
    "Neutral, Less Positive.\n",
    "\n",
    "<img src=\"Sentiment.png\" width=\"600\" height=\"\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26410b56",
   "metadata": {},
   "source": [
    "User anaylsis\n",
    "-------------\n",
    "\n",
    "Easy to score users for participation, contribution and response rate.\n",
    "Such an analysis might be considered a bit intrusive, but is potentially\n",
    "very useful for individual users who wish to see how much they\n",
    "contribute and how visible they are within a online community like this.\n",
    "It could also be used by administrators to track whether individuals\n",
    "were taking part, if they were contributing or if they were dominating. Here we can see the number of total messages sent per user, the average sentiment rating for those users and a calcuation of whether they were a net giver or taker based on whether they asked more questions or replied to more threads. \n",
    "\n",
    "<img src=\"Usersbynoofmessages.png\" width=\"600\" height=\"\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288f2b56",
   "metadata": {},
   "source": [
    "\n",
    "Topic analysis\n",
    "--------------\n",
    "\n",
    "Despite road-testing several models, I couldn’t get results that\n",
    "produced much useful information on the type of topics covered using the\n",
    "unsupervised tools commonly applied to similar formats (such as\n",
    "twitter). Some approaches tried were: \n",
    "\n",
    "1. NLTK's Keyword.TF-IDF analysis produced a 'score' of the words based on their frequency within sentences. However, the list of words alone offered little insight. The scoring system may have been more useful if the list of words generated could have been linked back to the individual posts within the main dataframe. However, this was challenging to do and was not achieved within the timeframe. \n",
    "\n",
    "2. As part of the above process I also ran the whole text through NLTK's word tokenizer. On its own knowing whether the words used were verbs or nouns was of little use. Again, may have been more useful information if it could have been brought back into the main dataframe and re-associated with the individual posts and threads. \n",
    "\n",
    "There are several likely reasons for this. One is the disjointed nature\n",
    "of the conversations and difficulty of grouping the conversations\n",
    "effectively. Another is that there was a lot of noise in the text that I\n",
    "was only partially successful in cleaning up. The lists of topics and\n",
    "words that were generated by these tools were, as such, often peppered\n",
    "with non-words and characters that inhibited a proper functioning of the\n",
    "algorithm. What was produced made little sense.\n",
    "\n",
    "The best indicators of topic are given by analysis of questions, brand\n",
    "meantions (urls) and counts of phrasal nouns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757af6c1",
   "metadata": {},
   "source": [
    "Links and Brand Mentions\n",
    "------------------------\n",
    "\n",
    "Url stems are a good proxy for brand mentions. Few entities get a mention without being linked to in thie kind of environment. \n",
    "\n",
    "<img src=\"LinkStems.png\" width=\"600\" height=\"\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fa0fc8",
   "metadata": {},
   "source": [
    "Repetitions of phrasal-nouns\n",
    "-----------\n",
    "\n",
    "As part of the topic analysis I ran the texts through N-gram functions\n",
    "and noun-phrase extractors. These provided some information about topic,\n",
    "but were most useful for generating lists of repeated issues. Here is\n",
    "some useful information for channel admins, who can see the frequency\n",
    "with which a topic is repeated. This might prompt them to open a new\n",
    "channel on the topic or to provide the information in a different\n",
    "format. A good example in this chat is the number of times that calls to\n",
    "complete the student survey were made. Admins might consider automating\n",
    "this weekly call to action. Here is a list of repeated topics:\n",
    "\n",
    "<img src=\"RepeatedNouns.png\" width=\"600\" height=\"\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03265619",
   "metadata": {},
   "source": [
    "\n",
    "The shape of the conversation\n",
    "-----------------------------\n",
    "\n",
    "The model does allow for some analysis of the shape of even if not the\n",
    "exact content of the conversation. We can see how spread-out user\n",
    "participation was: whether it was dominated by a few individuals or\n",
    "widely used by all. We can see if there were individuals who had low\n",
    "participation rates. We can also see what kind of initial message\n",
    "prompted most of a reaction and of course we can track the sentiment of\n",
    "a conversation (Although not so relevant in an harmonious group, this\n",
    "could be a very important issue in another context). Here we see some other useful indicators in use of emojis and the percentage of messages that are questions. More such measures would be possible if needed. For example, counting 'ha's for houmour or 'thanks' for gratitude. \n",
    "\n",
    "<img src=\"Theshapeofchat.png\" width=\"600\" height=\"\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a03e98",
   "metadata": {},
   "source": [
    "Conclusion \n",
    "----------\n",
    "\n",
    "Although a little disappointed with the noun-phrase and n-gram analysis\n",
    "methods as tools to categorise topic, it is easy to see how this model\n",
    "could be effectively applied to a larger set of data to monitor the\n",
    "health of the conversation against a range of different factors. These\n",
    "include:\n",
    "\n",
    "-   Participation rates\n",
    "\n",
    "-   Overall mood of a group\n",
    "\n",
    "-   Repeat topics that could be handled elsewhere\n",
    "\n",
    "-   Brand mentions\n",
    "\n",
    "Links and further reading\n",
    "-------------------------\n",
    "\n",
    "The Tableau story with these charts: https://public.tableau.com/shared/Q665YJ25J?:display_count=y&:origin=viz_share_link\n",
    "\n",
    "Link to Presentation: https://docs.google.com/presentation/d/1kI5ScVAIvYb4CJPWhzOsSY5aglKS8_gVbLzI1iOH57s/edit?usp=sharing\n",
    "\n",
    "\n",
    "1.  <https://medium.com/stratifyd/how-to-use-data-analytics-on-chat-sessions-a56bd2da72b0>\n",
    "\n",
    "2.  Analysing a non-committal relationship on WhatsApp. Good for some\n",
    "    basic KPI ideas:\n",
    "    <https://medium.com/swlh/chat-analysis-on-whatsapp-part-1-text-analysis-and-data-visualization-with-r-3a7e4e8362f2>\n",
    "\n",
    "3.  The ‘science’ of conversation analysis. How to open ‘slots’ for\n",
    "    conversation: [Opening ‘slots’ for people to make productive\n",
    "    contributions](https://www.sciencefocus.com/science/a-scientists-guide-to-life-how-to-be-a-better-conversationalist/)\n",
    "\n",
    "4.  Ted Talk by Elizabeth Stokoe. – Conversational analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad219955",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
